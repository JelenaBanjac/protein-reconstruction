{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding angles with gradient descent (projections & quaternions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Michaël Defferrard](https://deff.ch), EPFL LTS2  \n",
    "[Laurène Donati](https://people.epfl.ch/laurene.donati), EPFL BIG  \n",
    "[Jelena Banjac](https://people.epfl.ch/jelena.banjac), EPFL MSc in Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: To use the exr data format, please install the OpenEXR package following the instructions detailed in the README at github.com/tensorflow/graphics.\n",
      "Warning: To use the threejs_vizualization, please install the colabtools package following the instructions detailed in the README at github.com/tensorflow/graphics.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import h5py\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import seaborn as sns; sns.set(style=\"white\", color_codes=True)\n",
    "import ipyvolume as ipv\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from cryoem.plots import plot_projection, plot_projections\n",
    "from cryoem.projections import RotationMatrix\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow_graphics.util import asserts\n",
    "from tensorflow_graphics.math import vector\n",
    "from tensorflow_graphics.util import safe_ops\n",
    "from tensorflow_graphics.util import shape\n",
    "from tensorflow_graphics.geometry.transformation import quaternion, euler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1244838032406520743\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7636769353702659277\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '../data/bgal/bgal_ProjectionsAngles_ProjNber5000_AngCoverage2.0,0.4,2.0_AngShift0.0,0.0,0.0.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-288eb958fed6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprojections_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"bgal_ProjectionsAngles_ProjNber5000_AngCoverage{angle_ranges}_AngShift{angle_shift}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# load structures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{projections_filename}.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data['Projections'].shape[0]} projections of images with dimension {data['Projections'].shape[1:]} pixels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/protein_reconstruction/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/protein_reconstruction/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '../data/bgal/bgal_ProjectionsAngles_ProjNber5000_AngCoverage2.0,0.4,2.0_AngShift0.0,0.0,0.0.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "angle_ranges = \"2.0,0.4,2.0\"\n",
    "angle_shift = \"0.0,0.0,0.0\"\n",
    "dir_name = \"../data/bgal/\"\n",
    "projections_filename = f\"bgal_ProjectionsAngles_ProjNber5000_AngCoverage{angle_ranges}_AngShift{angle_shift}\"\n",
    "# load structures\n",
    "data = h5py.File(os.path.join(dir_name, f\"{projections_filename}.h5\"), 'r')\n",
    "\n",
    "print(f\"{data['Projections'].shape[0]} projections of images with dimension {data['Projections'].shape[1:]} pixels\")\n",
    "print(f\"{data['Angles'].shape[0]} sets of {data['Angles'].shape[1]} ground truth angles of corresponding projection images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "all_vectors = RotationMatrix(data[\"Angles\"])\n",
    "ipv.figure(width=500, height=500)\n",
    "ipv.pylab.xlim(-1, 1)\n",
    "ipv.pylab.ylim(-1, 1)\n",
    "ipv.pylab.zlim(-1, 1)\n",
    "ipv.scatter(all_vectors[:,0], all_vectors[:,2], all_vectors[:,1], marker=\"sphere\", color=\"blue\", size=1)\n",
    "ipv.pylab.save(f\"data/angle_variety/{angle_ranges}.html\")\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predicted Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_ang = [np.float64(x)*np.pi for x in angle_shift.split(\",\")]\n",
    "high_ang = [np.float64(x)*np.pi for x in angle_ranges.split(\",\")]\n",
    "\n",
    "euler = np.random.uniform(low=[low_ang[0], low_ang[1], low_ang[2]], \n",
    "                          high=[high_ang[0], high_ang[1], high_ang[2]],\n",
    "                          size=(n_samples, 3))\n",
    "\n",
    "angles_predicted = [tf.Variable(e, constraint=lambda x: tf.clip_by_value(x, tf.constant(low_ang), tf.constant(high_ang))) for e in euler]\n",
    "print(f\"Angles predicted: (min, max) = ({tf.reduce_min(angles_predicted):.4f}, {tf.reduce_max(angles_predicted):.4f})\")\n",
    "\n",
    "angles_predicted = np.array(angles_predicted)\n",
    "angles_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_predicted_plot = np.array([ np.array([(y%(2*np.pi)) for y in x.numpy()]) for x in angles_predicted])\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(17,7))\n",
    "axs[0].set_xlim(0,2*np.pi)\n",
    "axs[1].set_xlim(0,2*np.pi)\n",
    "axs[2].set_xlim(0,2*np.pi)\n",
    "plt.suptitle(\"Initialized Predicted Angles Count\")\n",
    "\n",
    "sns.distplot(angles_predicted_plot[:,0], kde=False, bins=40, ax=axs[0], axlabel=\"Z1 axis angle rotation [rad]\", color=\"r\")\n",
    "sns.distplot(angles_predicted_plot[:,1], kde=False, bins=40, ax=axs[1], axlabel=\"Y2 axis angle rotation [rad]\", color=\"g\")\n",
    "sns.distplot(angles_predicted_plot[:,2], kde=False, bins=40, ax=axs[2], axlabel=\"Z3 axis angle rotation [rad]\", color=\"b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### True Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "angles_true = np.reshape(data[\"Angles\"], (data[\"Angles\"].shape[0], -1))\n",
    "print(f\"Angles true: (min, max) = ({np.min(angles_true):.4f}, {np.max(angles_true):.4f})\")\n",
    "\n",
    "angles_true = np.array(angles_true)\n",
    "angles_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(17,7))\n",
    "axs[0].set_xlim(0,2*np.pi)\n",
    "axs[1].set_xlim(0,2*np.pi)\n",
    "axs[2].set_xlim(0,2*np.pi)\n",
    "plt.suptitle(\"True Angles Count\")\n",
    "\n",
    "sns.distplot(angles_true[:,0], kde=False, bins=40, ax=axs[0], axlabel=\"Z1 axis angle rotation [rad]\", color=\"r\")\n",
    "sns.distplot(angles_true[:,1], kde=False, bins=40, ax=axs[1], axlabel=\"Y2 axis angle rotation [rad]\", color=\"g\")\n",
    "sns.distplot(angles_true[:,2], kde=False, bins=40, ax=axs[2], axlabel=\"Z3 axis angle rotation [rad]\", color=\"b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = np.reshape(data[\"Projections\"], (data[\"Projections\"].shape[0], -1))\n",
    "print(f\"Projections: lenght = {len(projections)} (min, max) = ({np.min(projections):.4f}, {np.max(projections):.4f})\")\n",
    "projections = np.array(projections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Angle Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler2quaternion(angles):\n",
    "    \"\"\"\n",
    "    Quaternion implements 3 rotations along x, y, z axis. \n",
    "    We compose them to get the final (single) rotation.\n",
    "    \"\"\"\n",
    "    with tf.compat.v1.name_scope(None, \"quaternion_from_euler\", [angles]):\n",
    "        #print(angles)\n",
    "        a = [angles[i] for i in range(len(angles))]\n",
    "\n",
    "        a = tf.convert_to_tensor(value=a)\n",
    "\n",
    "        shape.check_static(tensor=a, tensor_name=\"angles\", has_dim_equals=(-1, 3))\n",
    "\n",
    "        half_angles = a / 2.0\n",
    "        cos_half_angles = tf.cos(half_angles)\n",
    "        sin_half_angles = tf.sin(half_angles)\n",
    "        c1, c2, c3 = tf.unstack(cos_half_angles, axis=-1)\n",
    "        s1, s2, s3 = tf.unstack(sin_half_angles, axis=-1)\n",
    "        # Tait-Bryan angles\n",
    "        #w = c1 * c2 * c3 + s1 * s2 * s3\n",
    "        #x = -c1 * s2 * s3 + s1 * c2 * c3\n",
    "        #y = c1 * s2 * c3 + s1 * c2 * s3\n",
    "        #z = -s1 * s2 * c3 + c1 * c2 * s3\n",
    "        \n",
    "        # Euler angles\n",
    "        w = c1*c2*c3 - s1*c2*s3\n",
    "        x = c1*s2*s3 - s1*s2*c3\n",
    "        y = c1*s2*c3 + s1*s2*s3\n",
    "        z = c1*c2*s3 + s1*c2*c3\n",
    "        return tf.stack((x, y, z, w), axis=-1)\n",
    "\n",
    "def d_q(q1, q2):\n",
    "     with (tf.compat.v1.name_scope(None, \"quaternion_relative_angle\",[q1, q2])):\n",
    "        q1 = tf.convert_to_tensor(value=q1)\n",
    "        q2 = tf.convert_to_tensor(value=q2)\n",
    "      \n",
    "        shape.check_static(\n",
    "            tensor=q1, tensor_name=\"quaternion1\", has_dim_equals=(-1, 4))\n",
    "        shape.check_static(\n",
    "            tensor=q2, tensor_name=\"quaternion2\", has_dim_equals=(-1, 4))\n",
    "\n",
    "        q1 = quaternion.normalize(q1)\n",
    "        q2 = quaternion.normalize(q2)\n",
    "        \n",
    "        dot_product = vector.dot(q1, q2, keepdims=False)\n",
    "        \n",
    "        # Ensure dot product is in range [-1. 1].\n",
    "        const = 1.8 #4.0 #.63\n",
    "        eps_dot_prod = const * asserts.select_eps_for_addition(dot_product.dtype)\n",
    "        dot_product = safe_ops.safe_shrink(\n",
    "            dot_product, -1, 1, open_bounds=False, eps=eps_dot_prod)\n",
    "\n",
    "        return 2.0 * tf.acos(tf.abs(dot_product)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.reduce_mean(d_q(euler2quaternion(angles_true[:,0:5]), euler2quaternion(angles_true[:,0:5]))) < 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.reduce_mean(d_q(euler2quaternion(angles_predicted[0:4]), euler2quaternion(angles_predicted[0:4]))) < 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (d_q(euler2quaternion([np.pi/2]*3), euler2quaternion([2*np.pi-np.pi/2]*3))-np.pi) < 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projection Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_p(p1, p2):\n",
    "    # (learned) distance between two images.\n",
    "    # for now, Euclid dist\n",
    "    p1 = tf.convert_to_tensor(value=p1, dtype=np.float64)\n",
    "    p2 = tf.convert_to_tensor(value=p2, dtype=np.float64)\n",
    "\n",
    "    if len(p1.shape) > 1:\n",
    "        dist = tf.norm(p1-p2, ord='euclidean', axis=1, keepdims=True)\n",
    "    else:\n",
    "        dist = tf.norm(p1-p2, ord='euclidean')\n",
    "\n",
    "    return dist\n",
    "\n",
    "assert tf.reduce_mean(d_p(projections[0:3], projections[0:3])) < 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN of the Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_knn_output(k):\n",
    "#     start_time = time()\n",
    "\n",
    "#     name = projections_filename.split('/')[-1]\n",
    "#     if not os.path.exists(f'data/{name}_distances.npy'):\n",
    "#         nbrs = NearestNeighbors(n_neighbors=k, metric=d_p, algorithm='ball_tree', n_jobs=-1).fit(projections)\n",
    "#         distances_p, indices_p = nbrs.kneighbors(projections)\n",
    "#         A_p = nbrs.kneighbors_graph(projections).toarray()\n",
    "\n",
    "#         try:\n",
    "#             np.save(f'data/{name}_indices', indices_p)         # Indices of the nearest points in the population matrix\n",
    "#             np.save(f'data/{name}_distances', distances_p)     # Array representing the lengths to points\n",
    "#             np.save(f'data/{name}_A', A_p)                     # Sparse graph showing the connections between neighboring points\n",
    "#         except:\n",
    "#             pass\n",
    "#         print(f\"--- {time() - start_time} seconds ---\")\n",
    "    \n",
    "#     else:\n",
    "#         indices_p     = np.load(f'data/{name}_indices.npy')     # shape: NUM_IMGS, NUM_NEIGHBOURS\n",
    "#         distances_p   = np.load(f'data/{name}_distances.npy')   # shape: NUM_IMGS, NUM_NEIGHBOURS\n",
    "#         A_p           = np.load(f'data/{name}_A.npy')           # shape: NUM_IMGS, NUM_IMGS\n",
    "\n",
    "    \n",
    "#     return indices_p, distances_p, A_p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices_p, distances_p, A_p = get_knn_output(k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(distances_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare d_Q and d_P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Slope & Intercept from kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_p_list = []\n",
    "# d_q_list = []\n",
    "\n",
    "# for indices in indices_p:\n",
    "#     for jidx, j in enumerate(indices[1:], start=1):\n",
    "#         i = indices[0]\n",
    "        \n",
    "#         # Get distance between 2 projections (already calculated in kNN)\n",
    "#         distance_target_p = distances_p[i][jidx] \n",
    "#         # Collect projection distance for plotting\n",
    "#         d_p_list.append(distance_target_p)\n",
    "\n",
    "#         # Convert 2 angles to 2 corresponding quaternions\n",
    "#         a1 = angles_true[i]\n",
    "#         a2 = angles_true[j]\n",
    "#         q1 = euler2quaternion(a1)\n",
    "#         q2 = euler2quaternion(a2)\n",
    "#         # Calculate the distance between 2 quaternions\n",
    "#         distance_target_q = d_q(q1, q2)\n",
    "#         # Collect quaternion distance for plotting\n",
    "#         d_q_list.append(distance_target_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating the dataframe for SNS plot\n",
    "# data = {\"d_Q\" : [x.numpy() for x in d_q_list],\n",
    "#         \"d_P\" : d_p_list}\n",
    "# df = pd.DataFrame(data=data)\n",
    "# df = df[df.d_Q < 1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.jointplot(xlim=(0,np.pi), x=\"d_Q\", y=\"d_P\", data=df, kind=\"reg\", color=\"g\", height=11, scatter_kws={\"s\": 1})  # \"reg\", \"kde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.jointplot(x=\"d_Q\", y=\"d_P\", data=df, kind=\"kde\", color=\"g\", height=11)  # \"reg\", \"kde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(17,10))\n",
    "# g = sns.distplot(df[\"d_Q\"], ax=ax);\n",
    "\n",
    "# X=g.get_lines()[0].get_xdata()# x-coordinate of points along the regression line\n",
    "# Y=g.get_lines()[0].get_ydata()# y-coordinate\n",
    "# plt.plot(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dQ_mean = df.describe().iloc[1,0]\n",
    "# # dP_mean = df.describe().iloc[1,1]\n",
    "# # slope = dP_mean/dQ_mean\n",
    "# # intercept = 0\n",
    "\n",
    "# from scipy.stats import linregress\n",
    "# lr = linregress(df.d_Q, df.d_P)\n",
    "# slope, intercept = lr.slope, lr.intercept\n",
    "# print(f\"d_P/d_Q = {slope}, intercept = {intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slope & Intercept from 1 compared to n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting data for the plot where the result shows how 1 image changes distance in comparison to all the others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Plot convergence.\n",
    "# all_q_dist = []\n",
    "# all_p_dist = []\n",
    "# time_start = time()\n",
    "\n",
    "# d_q_list = []\n",
    "# d_p_list = []\n",
    "\n",
    "# # Take the first image\n",
    "# i = 0\n",
    "\n",
    "# # Sample some pairs.\n",
    "# idx1 = list([i]*5000)\n",
    "# idx2 = list(range(5000))\n",
    "\n",
    "# # Compute distances between quaternions\n",
    "# a1 = [angles_true[i] for i in idx1]\n",
    "# a2 = [angles_true[i] for i in idx2]\n",
    "# q1 = euler2quaternion(a1)\n",
    "# q2 = euler2quaternion(a2)\n",
    "# distance_target_q = d_q(q1, q2)\n",
    "# d_q_list.append(distance_target_q)\n",
    "\n",
    "# # Compute distances between projections\n",
    "# p1 = [projections[i] for i in idx1]\n",
    "# p2 = [projections[i] for i in idx2]\n",
    "# distance_target_p = d_p(p1, p2)\n",
    "# d_p_list.append(distance_target_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,7))\n",
    "# plt.plot(d_q_list[0], d_p_list[0], marker=\"*\", markersize=2, lw=0)   \n",
    "# plt.xlabel('d_Q')\n",
    "# plt.ylabel('d_P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating the dataframe for SNS plot\n",
    "# data = {\"d_Q\" : list(d_q_list[0].numpy()),\n",
    "#         \"d_P\" : [x for x in d_p_list[0].numpy().T[0]]}\n",
    "# df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.jointplot(x=\"d_Q\", y=\"d_P\", data=df, kind=\"reg\", color=\"g\", height=7)  # \"reg\", \"kde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slope, intercept, r_value, p_value, slope_std_error = stats.linregress(df[\"d_Q\"],df[\"d_P\"])\n",
    "# print(f\"d_P/d_Q = {slope}, intercept = {intercept}\")\n",
    "# # dP = slope*dQ + intercept\n",
    "# # => dQ = (dP-intercept)/slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Slope & Intercept from m to all n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting data for the plot where the result shows how several images change (m=10) distance in comparison to all the others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot convergence.\n",
    "all_q_dist = []\n",
    "all_p_dist = []\n",
    "time_start = time()\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "ITERATIONS = 5000\n",
    "\n",
    "for i in range(0, ITERATIONS, 500):\n",
    "    d_q_list = []\n",
    "    d_p_list = []\n",
    "\n",
    "    # Sample some pairs.\n",
    "    idx1 = list([i]*5000)\n",
    "    idx2 = list(range(5000))\n",
    "    \n",
    "    # Compute distances between quaternions\n",
    "    a1 = [angles_true[i] for i in idx1]\n",
    "    a2 = [angles_true[i] for i in idx2]\n",
    "    q1 = euler2quaternion(a1)\n",
    "    q2 = euler2quaternion(a2)\n",
    "    distance_target_q = d_q(q1, q2)\n",
    "\n",
    "    # Compute distances between projections\n",
    "    p1 = [projections[i] for i in idx1]\n",
    "    p2 = [projections[i] for i in idx2]\n",
    "    distance_target_p = d_p(p1, p2)\n",
    "\n",
    "    all_q_dist.extend([x.numpy() for x in distance_target_q])\n",
    "    all_p_dist.extend([x.numpy()[0] for x in distance_target_p])\n",
    "    \n",
    "    plt.plot(distance_target_q, distance_target_p, marker=\"*\", markersize=2, lw=0)\n",
    "    \n",
    "plt.xlabel('d_Q')\n",
    "plt.ylabel('d_P');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataframe for SNS plot\n",
    "data = {\"d_Q\" : all_q_dist,\n",
    "        \"d_P\" : all_p_dist}\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"d_Q\", y=\"d_P\", data=df, kind=\"reg\", color=\"g\", height=11)  # \"reg\", \"kde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"d_Q\", y=\"d_P\", data=df, kind=\"kde\", color=\"g\", height=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Polyfit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs4dP = np.polyfit(df[\"d_Q\"], df[\"d_P\"], deg=14)\n",
    "convert2dP = np.poly1d(coeffs4dP)\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.plot(df[\"d_Q\"], df[\"d_P\"], marker=\"*\", markersize=5, lw=0)\n",
    "plt.plot(df[\"d_Q\"], convert2dP(df[\"d_Q\"]), marker=\"*\", markersize=2, lw=0, c=\"r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to then optimize\n",
    "$$ \\operatorname*{arg\\,min}_{\\{\\hat{Q}_i\\}_{i=1}^n} \\sum_{\\{i,j |d_p(p_i, p_j) < \\epsilon\\}} \\left| d_p(p_i, p_j) - d_Q(\\hat{Q}_i, \\hat{Q}_j) \\right|^2, $$\n",
    "where $p_i$ is a projected image and $d_p$ is a (learned) distance between two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(a1_predicted, a2_predicted, distance_target, dt_type, space):\n",
    "    a1_predicted = list(a1_predicted)\n",
    "    a2_predicted = list(a2_predicted)\n",
    "    \n",
    "    q1 = euler2quaternion(a1_predicted)\n",
    "    q2 = euler2quaternion(a2_predicted)\n",
    "    \n",
    "    distance = d_q(q1, q2)\n",
    "    \n",
    "    if space == \"dQspace\":\n",
    "        if dt_type == \"dP\":\n",
    "            # Convert dP to dQ\n",
    "            distance_target = (distance_target-intercept)/slope\n",
    "            \n",
    "    elif space == \"dPspace\":\n",
    "        if dt_type == \"dP\":\n",
    "            # Convert dQ to dP\n",
    "            distance = tf.math.polyval(coeffs4dP, distance)\n",
    "        elif dt_type == \"dQ\":\n",
    "            distance = tf.math.polyval(coeffs4dP, distance)\n",
    "            distance_target = tf.math.polyval(coeffs4dP, distance_target)  \n",
    "\n",
    "    # The mean doesn't depend on the batch size.\n",
    "    return tf.reduce_mean((distance - distance_target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(a1_predicted, a2_predicted, distance_target, dt_type, space):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(a1_predicted, a2_predicted, distance_target, dt_type, space)\n",
    "        gradient = tape.gradient(loss_value, a1_predicted + a2_predicted)\n",
    "        \n",
    "    return loss_value, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_predicted_vs_true_angle(steps, batch_size, optimization=False):\n",
    "    losses = np.empty(steps)\n",
    "    time_start = time()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    for step in range(1, steps+1):\n",
    "\n",
    "        # Sample some pairs.\n",
    "        idx1, idx2 = sample_pairs(n_samples, batch_size, style=\"random\")\n",
    "    \n",
    "        a1 = [angles_predicted[i] for i in idx1]\n",
    "        a2 = [angles_predicted[i] for i in idx2]\n",
    "\n",
    "        # Compute distances between true quaternions\n",
    "        a1_true = [angles_true[i] for i in idx1]\n",
    "        a2_true = [angles_true[i] for i in idx2]\n",
    "        q1_true = euler2quaternion(a1_true)\n",
    "        q2_true = euler2quaternion(a2_true)\n",
    "        \n",
    "        distance_target = d_q(q1_true, q2_true)\n",
    "\n",
    "        # Optimize by gradient descent.\n",
    "        if optimization:\n",
    "            losses[step-1], gradients = gradient(a1, a2, distance_target, dt_type=\"dQ\", space=\"dQspace\")\n",
    "            optimizer.apply_gradients(zip(gradients, a1 + a2))\n",
    "        else:\n",
    "            losses[step-1] = loss(a1, a2, distance_target, dt_type=\"dQ\", space=\"dQspace\")\n",
    "        \n",
    "        # Periodically report progress.\n",
    "#         if ((step % (steps//10)) == 0) or (step == steps):\n",
    "#             time_elapsed = time() - time_start\n",
    "#             #loss_mean = np.mean(losses[(step-1)-(steps//10):step-1])\n",
    "#             print(f'step {step}/{steps} ({time_elapsed:.0f}s): loss = {losses[step-1]:.2e}')\n",
    "\n",
    "    if optimization:\n",
    "        # Plot convergence.\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(np.linspace(0, time()-time_start, steps), losses)\n",
    "        ax.set_xlabel('time [s]')\n",
    "        ax.set_ylabel('loss');\n",
    "    else:\n",
    "        print(f\"Mean GT loss: {np.mean(losses)}\")\n",
    "        return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pairs(n_samples, batch_size, style=\"random\", k=None):\n",
    "    if not k and style != \"random\":\n",
    "        raise ValueError(\"Please specify k for kNN for sample_pairs method\")\n",
    "    \n",
    "    if style==\"random\":\n",
    "        idx1 = list(np.random.randint(0, n_samples, batch_size))\n",
    "        idx2 = list(np.random.randint(0, n_samples, batch_size))\n",
    "    \n",
    "    elif style==\"knn\":\n",
    "        idx1 = list(np.random.randint(0, n_samples, batch_size))\n",
    "        indices_p, distances_p, A_p = get_knn_output(k=k)\n",
    "        idx2 = [indices_p[i][np.random.randint(1, k)] for i in idx1]\n",
    " \n",
    "    elif style==\"knn_and_random\":\n",
    "        # select random sample for the first element of pair\n",
    "        idx1 = list(np.random.randint(0, n_samples, batch_size))\n",
    "        \n",
    "        # half from kNN\n",
    "        indices_p, distances_p, A_p = get_knn_output(k=k)\n",
    "        idx2_knn = [indices_p[i][np.random.randint(1, k)] for i in idx1[:batch_size//2]]\n",
    "        idx2_random = list(np.random.randint(0, n_samples, batch_size//2))\n",
    "        # half random\n",
    "        idx2 = idx2_knn + idx2_random\n",
    "        \n",
    "    return idx1, idx2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What should be the minimum optimization loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_opt_loss(steps, batch_size):\n",
    "    losses = np.empty(steps)\n",
    "    time_start = time()\n",
    "     \n",
    "    for step in range(1, steps+1):\n",
    "\n",
    "        # Sample some pairs.\n",
    "        idx1, idx2 = sample_pairs(n_samples, batch_size, style=\"random\")\n",
    "\n",
    "        # Compute distances between projections\n",
    "        p1 = [projections[i] for i in idx1]\n",
    "        p2 = [projections[i] for i in idx2]\n",
    "\n",
    "        distance_target = d_p(p1, p2)\n",
    "\n",
    "        a1 = [angles_true[i] for i in idx1]\n",
    "        a2 = [angles_true[i] for i in idx2]\n",
    "\n",
    "        # Optimize by gradient descent.\n",
    "        losses[step-1] = loss(a1, a2, distance_target, dt_type=\"dP\", space=\"dPspace\")\n",
    "        \n",
    "        # Periodically report progress.\n",
    "        if ((step % (steps//10)) == 0) or (step == steps):\n",
    "            time_elapsed = time() - time_start\n",
    "            print(f'step {step}/{steps} ({time_elapsed:.0f}s): loss = {losses[step-1]:.2e}')\n",
    "        \n",
    "    else:\n",
    "        print(f\"Mean loss: {np.mean(losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection vs. angle_true\n",
    "min_opt_loss(steps=500, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization loop (projection-true & angles-predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Before] Prediction vs. True Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_predicted_plot = np.array([ np.array([(y%(2*np.pi)) for y in x.numpy()]) for x in angles_predicted])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(17,7))\n",
    "axs[0].set_xlim(0,2*np.pi)\n",
    "axs[1].set_xlim(0,2*np.pi)\n",
    "axs[2].set_xlim(0,2*np.pi)\n",
    "plt.suptitle(\"Predicted Angles Count\")\n",
    "\n",
    "sns.distplot(angles_predicted_plot[:,0], kde=False, bins=20, ax=axs[0], axlabel=\"Z1 axis angle rotation [rad]\", color=\"r\")\n",
    "sns.distplot(angles_predicted_plot[:,1], kde=False, bins=20, ax=axs[1], axlabel=\"Y2 axis angle rotation [rad]\", color=\"g\")\n",
    "sns.distplot(angles_predicted_plot[:,2], kde=False, bins=80, ax=axs[2], axlabel=\"Z3 axis angle rotation [rad]\", color=\"b\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_predicted_vs_true_angle(steps=2000, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=10000\n",
    "batch_size=256\n",
    "\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "losses = np.empty(steps)\n",
    "gt_losses = []\n",
    "time_start = time()\n",
    "\n",
    "try:\n",
    "    for step in range(1, steps+1):\n",
    "\n",
    "        # Sample some pairs.\n",
    "        idx1, idx2 = sample_pairs(n_samples, batch_size, style=\"random\")\n",
    "\n",
    "        # Compute distances between projections\n",
    "        p1 = [projections[i] for i in idx1]\n",
    "        p2 = [projections[i] for i in idx2]\n",
    "\n",
    "        distance_target = d_p(p1, p2)\n",
    "\n",
    "        a1 = [angles_predicted[i] for i in idx1]\n",
    "        a2 = [angles_predicted[i] for i in idx2]\n",
    "\n",
    "        # Optimize by gradient descent.\n",
    "        losses[step-1], gradients = gradient(a1, a2, distance_target, dt_type=\"dP\", space=\"dPspace\")\n",
    "        optimizer.apply_gradients(zip(gradients, a1 + a2))\n",
    "\n",
    "        # Periodically report progress.\n",
    "        if ((step % (steps//10)) == 0) or (step == steps):\n",
    "            time_elapsed = time() - time_start\n",
    "            print(f'step {step}/{steps} ({time_elapsed:.0f}s): loss = {losses[step-1]:.2e}')\n",
    "            gt_loss = loss_predicted_vs_true_angle(steps=2000, batch_size=256)\n",
    "            gt_losses.append(gt_loss)\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    # Plot convergence.\n",
    "    fig, ax = plt.subplots(2)\n",
    "    ax[0].plot(np.linspace(0, time()-time_start, steps), losses)\n",
    "    ax[0].set_xlabel('time [s]')\n",
    "    ax[0].set_ylabel('loss');\n",
    "    ax[1].plot(np.arange(0, len(gt_losses)), gt_losses)\n",
    "    ax[1].set_xlabel('time [s]')\n",
    "    ax[1].set_ylabel('GT loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [After] Prediction vs. True Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_predicted_vs_true_angle(steps=2000, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_predicted_plot = np.array([ np.array([(y%(2*np.pi)) for y in x.numpy()]) for x in angles_predicted])\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(17,7))\n",
    "axs[0].set_xlim(0,2*np.pi)\n",
    "axs[1].set_xlim(0,2*np.pi)\n",
    "axs[2].set_xlim(0,2*np.pi)\n",
    "plt.suptitle(\"Predicted Angles Count\")\n",
    "\n",
    "sns.distplot(angles_predicted_plot[:,0], kde=False, bins=60, ax=axs[0], axlabel=\"Z1 axis angle rotation [rad]\", color=\"r\")\n",
    "sns.distplot(angles_predicted_plot[:,1], kde=False, bins=20, ax=axs[1], axlabel=\"Y2 axis angle rotation [rad]\", color=\"g\")\n",
    "sns.distplot(angles_predicted_plot[:,2], kde=False, bins=60, ax=axs[2], axlabel=\"Z3 axis angle rotation [rad]\", color=\"b\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "all_vectors = RotationMatrix(angles_predicted_plot)\n",
    "ipv.figure(width=500, height=500)\n",
    "ipv.pylab.xlim(-1, 1)\n",
    "ipv.pylab.ylim(-1, 1)\n",
    "ipv.pylab.zlim(-1, 1)\n",
    "ipv.scatter(all_vectors[:,0], all_vectors[:,2], all_vectors[:,1], marker=\"sphere\", color=\"blue\", size=1)\n",
    "ipv.pylab.save(f\"data/angle_variety/predicted_polyfit_30K_{angle_ranges}.html\")\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps=2000\n",
    "# batch_size=256\n",
    "\n",
    "# #optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# losses = np.empty(steps)\n",
    "# time_start = time()\n",
    "\n",
    "# try:\n",
    "#     for step in range(1, steps+1):\n",
    "\n",
    "#         # Sample some pairs.\n",
    "#         idx1, idx2 = sample_pairs(n_samples, batch_size, style=\"random\")\n",
    "\n",
    "#         # Compute distances between projections\n",
    "#         p1 = [projections[i] for i in idx1]\n",
    "#         p2 = [projections[i] for i in idx2]\n",
    "\n",
    "#         distance_target = d_p(p1, p2)\n",
    "\n",
    "#         a1 = [angles_predicted[i] for i in idx1]\n",
    "#         a2 = [angles_predicted[i] for i in idx2]\n",
    "\n",
    "#         # Optimize by gradient descent.\n",
    "#         losses[step-1], gradients = gradient(a1, a2, distance_target, dt_type=\"dP\", space=\"dPspace\")\n",
    "#         optimizer.apply_gradients(zip(gradients, a1 + a2))\n",
    "\n",
    "#         # Periodically report progress.\n",
    "#         if ((step % (steps//10)) == 0) or (step == steps):\n",
    "#             time_elapsed = time() - time_start\n",
    "#             print(f'step {step}/{steps} ({time_elapsed:.0f}s): loss = {losses[step-1]:.2e}')\n",
    "#             loss_predicted_vs_true_angle(steps=2000, batch_size=256)\n",
    "# except:\n",
    "#     pass\n",
    "# finally:\n",
    "#     # Plot convergence.\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(np.linspace(0, time()-time_start, steps), losses)\n",
    "#     ax.set_xlabel('time [s]')\n",
    "#     ax.set_ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angles_predicted_plot = np.array([ np.array([(y%(2*np.pi)) for y in x.numpy()]) for x in angles_predicted])\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(17,7))\n",
    "# axs[0].set_xlim(0,2*np.pi)\n",
    "# axs[1].set_xlim(0,2*np.pi)\n",
    "# axs[2].set_xlim(0,2*np.pi)\n",
    "# plt.suptitle(\"Predicted Angles Count\")\n",
    "\n",
    "# sns.distplot(angles_predicted_plot[:,0], kde=False, bins=60, ax=axs[0], axlabel=\"Z1 axis angle rotation [rad]\", color=\"r\")\n",
    "# sns.distplot(angles_predicted_plot[:,1], kde=False, bins=20, ax=axs[1], axlabel=\"Y2 axis angle rotation [rad]\", color=\"g\")\n",
    "# sns.distplot(angles_predicted_plot[:,2], kde=False, bins=60, ax=axs[2], axlabel=\"Z3 axis angle rotation [rad]\", color=\"b\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot\n",
    "# all_vectors = RotationMatrix(angles_predicted_plot)\n",
    "# ipv.figure(width=500, height=500)\n",
    "# ipv.pylab.xlim(-1, 1)\n",
    "# ipv.pylab.ylim(-1, 1)\n",
    "# ipv.pylab.zlim(-1, 1)\n",
    "# ipv.scatter(all_vectors[:,0], all_vectors[:,2], all_vectors[:,1], marker=\"sphere\", color=\"blue\", size=1)\n",
    "# ipv.pylab.save(f\"data/angle_variety/predicted_polyfit_30K_{angle_ranges}.html\")\n",
    "# ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps=2000\n",
    "# batch_size=256\n",
    "\n",
    "# #optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# losses = np.empty(steps)\n",
    "# time_start = time()\n",
    "\n",
    "# for step in range(1, steps+1):\n",
    "\n",
    "#     # Sample some pairs.\n",
    "#     idx1, idx2 = sample_pairs(n_samples, batch_size, style=\"random\")\n",
    "    \n",
    "#     # Compute distances between projections\n",
    "#     p1 = [projections[i] for i in idx1]\n",
    "#     p2 = [projections[i] for i in idx2]\n",
    "    \n",
    "#     distance_target = d_p(p1, p2)\n",
    "\n",
    "#     a1 = [angles_predicted[i] for i in idx1]\n",
    "#     a2 = [angles_predicted[i] for i in idx2]\n",
    "    \n",
    "#     # Optimize by gradient descent.\n",
    "#     losses[step-1], gradients = gradient(a1, a2, distance_target, dt_type=\"dP\", space=\"dPspace\")\n",
    "#     optimizer.apply_gradients(zip(gradients, a1 + a2))\n",
    "\n",
    "#     # Periodically report progress.\n",
    "#     if ((step % (steps//10)) == 0) or (step == steps):\n",
    "#         time_elapsed = time() - time_start\n",
    "#         print(f'step {step}/{steps} ({time_elapsed:.0f}s): loss = {losses[step-1]:.2e}')\n",
    "#         loss_predicted_vs_true_angle(steps=2000, batch_size=256)\n",
    "        \n",
    "# # Plot convergence.\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(np.linspace(0, time()-time_start, steps), losses)\n",
    "# ax.set_xlabel('time [s]')\n",
    "# ax.set_ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angles_predicted_plot = np.array([ np.array([(y%(2*np.pi)) for y in x.numpy()]) for x in angles_predicted])\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(17,7))\n",
    "# axs[0].set_xlim(0,2*np.pi)\n",
    "# axs[1].set_xlim(0,2*np.pi)\n",
    "# axs[2].set_xlim(0,2*np.pi)\n",
    "# plt.suptitle(\"Predicted Angles Count\")\n",
    "\n",
    "# sns.distplot(angles_predicted_plot[:,0], kde=False, bins=60, ax=axs[0], axlabel=\"Z1 axis angle rotation [rad]\", color=\"r\")\n",
    "# sns.distplot(angles_predicted_plot[:,1], kde=False, bins=20, ax=axs[1], axlabel=\"Y2 axis angle rotation [rad]\", color=\"g\")\n",
    "# sns.distplot(angles_predicted_plot[:,2], kde=False, bins=60, ax=axs[2], axlabel=\"Z3 axis angle rotation [rad]\", color=\"b\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot\n",
    "# all_vectors = RotationMatrix(angles_predicted_plot)\n",
    "# ipv.figure(width=500, height=500)\n",
    "# ipv.pylab.xlim(-1, 1)\n",
    "# ipv.pylab.ylim(-1, 1)\n",
    "# ipv.pylab.zlim(-1, 1)\n",
    "# ipv.scatter(all_vectors[:,0], all_vectors[:,2], all_vectors[:,1], marker=\"sphere\", color=\"blue\", size=1)\n",
    "# ipv.pylab.save(f\"data/angle_variety/predicted_polyfit_30K_{angle_ranges}.html\")\n",
    "# ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps=10000\n",
    "# batch_size=256\n",
    "\n",
    "# #optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# losses = np.empty(steps)\n",
    "# time_start = time()\n",
    "\n",
    "# for step in range(1, steps+1):\n",
    "\n",
    "#     # Sample some pairs.\n",
    "#     idx1, idx2 = sample_pairs(n_samples, batch_size, style=\"random\")\n",
    "    \n",
    "#     # Compute distances between projections\n",
    "#     p1 = [projections[i] for i in idx1]\n",
    "#     p2 = [projections[i] for i in idx2]\n",
    "    \n",
    "#     distance_target = d_p(p1, p2)\n",
    "\n",
    "#     a1 = [angles_predicted[i] for i in idx1]\n",
    "#     a2 = [angles_predicted[i] for i in idx2]\n",
    "    \n",
    "#     # Optimize by gradient descent.\n",
    "#     losses[step-1], gradients = gradient(a1, a2, distance_target, dt_type=\"dP\", space=\"dPspace\")\n",
    "#     optimizer.apply_gradients(zip(gradients, a1 + a2))\n",
    "\n",
    "#     # Periodically report progress.\n",
    "#     if ((step % (steps//10)) == 0) or (step == steps):\n",
    "#         time_elapsed = time() - time_start\n",
    "#         print(f'step {step}/{steps} ({time_elapsed:.0f}s): loss = {losses[step-1]:.2e}')\n",
    "#         loss_predicted_vs_true_angle(steps=2000, batch_size=256)\n",
    "        \n",
    "# # Plot convergence.\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(np.linspace(0, time()-time_start, steps), losses)\n",
    "# ax.set_xlabel('time [s]')\n",
    "# ax.set_ylabel('loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
