{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding angles with gradient descent (projections & quaternions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import h5py\n",
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow_graphics.geometry.transformation import quaternion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Angles / Quaternions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_ang = np.pi/2\n",
    "high_ang = 2*np.pi-np.pi/2\n",
    "\n",
    "euler = np.random.uniform(low=[low_ang, low_ang, low_ang], \n",
    "                          high=[high_ang, high_ang, high_ang],\n",
    "                          size=(n_samples,3))\n",
    "angles_true = [quaternion.from_euler(e) for e in euler]\n",
    "\n",
    "print(f'{len(angles_true)} tensors of shape {angles_true[0].shape}')\n",
    "\n",
    "# Sanity check: the quaternions represent rotations, i.e., are normalized.\n",
    "assert abs(tf.reduce_mean(tf.norm(angles_true, axis=1) - tf.ones(n_samples, dtype=np.float64))) < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_true = np.array(angles_true)\n",
    "angles = np.reshape(angles_true, (angles_true.shape[0], -1))\n",
    "angles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of *.h5 files\n",
    "data_dir = \"../data\"\n",
    "\n",
    "# half coverage (AngCoverage=0.5)\n",
    "projections_filename = \"ProjectionsAngles_ProjNber5000_AngCoverage0.5_AngShift1.57\"\n",
    "\n",
    "# load structures\n",
    "data = h5py.File(os.path.join(data_dir, f\"{projections_filename}.h5\"), 'r')\n",
    "\n",
    "print(f\"{data['Projections'].shape[0]} projections of images with dimension {data['Projections'].shape[1:]} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = np.reshape(data[\"Projections\"], (data[\"Projections\"].shape[0], -1))\n",
    "projections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pixels = projections.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Angle Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_graphics.util import asserts\n",
    "from tensorflow_graphics.math import vector\n",
    "from tensorflow_graphics.util import safe_ops\n",
    "from tensorflow_graphics.util import shape\n",
    "\n",
    "def d_q(q1, q2):\n",
    "     with (tf.compat.v1.name_scope(None, \"quaternion_relative_angle\",\n",
    "                                 [q1, q2])):\n",
    "        q1 = tf.convert_to_tensor(value=q1)\n",
    "        q2 = tf.convert_to_tensor(value=q2)\n",
    "      \n",
    "        shape.check_static(\n",
    "            tensor=q1, tensor_name=\"quaternion1\", has_dim_equals=(-1, 4))\n",
    "        shape.check_static(\n",
    "            tensor=q2, tensor_name=\"quaternion2\", has_dim_equals=(-1, 4))\n",
    "\n",
    "        q1 = quaternion.normalize(q1)\n",
    "        q2 = quaternion.normalize(q2)\n",
    "        \n",
    "        dot_product = vector.dot(q1, q2, keepdims=False)\n",
    "        \n",
    "        # Ensure dot product is in range [-1. 1].\n",
    "        const = 1.8 #4.0 #.63\n",
    "        eps_dot_prod = const * asserts.select_eps_for_addition(dot_product.dtype)\n",
    "        dot_product = safe_ops.safe_shrink(\n",
    "            dot_product, -1, 1, open_bounds=False, eps=eps_dot_prod)\n",
    "\n",
    "        return 2.0 * tf.acos(tf.abs(dot_product))\n",
    "    \n",
    "assert tf.reduce_mean(d_q(angles_true[0:3], angles_true[0:3])) < 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.reduce_mean(d_q(angles_true[0:3], angles_true[0:3])))\n",
    "print(tf.reduce_mean(quaternion.relative_angle(angles_true[0:3], angles_true[0:3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projection Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_p(p1, p2):\n",
    "    # (learned) distance between two images.\n",
    "    # for now, Euclid dist\n",
    "    p1 = tf.convert_to_tensor(value=p1, dtype=np.float32)\n",
    "    p2 = tf.convert_to_tensor(value=p2, dtype=np.float32)\n",
    "\n",
    "    if len(p1.shape) > 1:\n",
    "        dist = tf.norm(p1-p2, ord='euclidean', axis=1, keepdims=True)\n",
    "    else:\n",
    "        dist = tf.norm(p1-p2, ord='euclidean')\n",
    "\n",
    "    return dist\n",
    "\n",
    "assert tf.reduce_mean(d_p(projections[0:3], projections[0:3])) < 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_p(projections[0:3], projections[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjacency matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "projections_filename = \"projections1\"\n",
    "\n",
    "if not os.path.exists(f'data/{projections_filename}_distances.npy'):\n",
    "    nbrs = NearestNeighbors(n_neighbors=5, metric=d_p, algorithm='ball_tree').fit(projections)\n",
    "    distances_p, indices_p = nbrs.kneighbors(projections)\n",
    "    A_p = nbrs.kneighbors_graph(projections).toarray()\n",
    "    \n",
    "    np.save(f'data/{projections_filename}_indices', indices_p)         # Indices of the nearest points in the population matrix\n",
    "    np.save(f'data/{projections_filename}_distances', distances_p)     # Array representing the lengths to points\n",
    "    np.save(f'data/{projections_filename}_A', A_p) # Sparse graph showing the connections between neighboring points\n",
    "    \n",
    "else:\n",
    "    indices_p     = np.load(f'data/{projections_filename}_indices.npy')     # shape: NUM_IMGS, NUM_NEIGHBOURS\n",
    "    distances_p   = np.load(f'data/{projections_filename}_distances.npy')   # shape: NUM_IMGS, NUM_NEIGHBOURS\n",
    "    A_p           = np.load(f'data/{projections_filename}_A.npy') # shape: NUM_IMGS, NUM_IMGS\n",
    "    \n",
    "print(f\"--- {time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "angles_filename = \"angles1\"\n",
    "\n",
    "if not os.path.exists(f'data/{angles_filename}_distances.npy'):\n",
    "    nbrs = NearestNeighbors(n_neighbors=5, metric=d_q, algorithm='ball_tree').fit(angles)\n",
    "    distances_a, indices_a = nbrs.kneighbors(angles)\n",
    "    A_a = nbrs.kneighbors_graph(angles).toarray()\n",
    "    \n",
    "    np.save(f'data/{angles_filename}_indices', indices_a)         # Indices of the nearest points in the population matrix\n",
    "    np.save(f'data/{angles_filename}_distances', distances_a)     # Array representing the lengths to points\n",
    "    np.save(f'data/{angles_filename}_A', A_a) # Sparse graph showing the connections between neighboring points\n",
    "    \n",
    "else:\n",
    "    indices_a     = np.load(f'data/{angles_filename}_indices.npy')     # shape: NUM_IMGS, NUM_NEIGHBOURS\n",
    "    distances_a   = np.load(f'data/{angles_filename}_distances.npy')   # shape: NUM_IMGS, NUM_NEIGHBOURS\n",
    "    A_a           = np.load(f'data/{angles_filename}_A.npy') # shape: NUM_IMGS, NUM_IMGS\n",
    "    \n",
    "print(f\"--- {time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To normalize our distances, we simply calculate the following:\n",
    "\n",
    "$$ z_{i} = \\frac{d_i - min(d)}{max(d) - min(d)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(min_val, max_val):\n",
    "    def _inner_normalize(dist):\n",
    "        return (dist - min_val)/(max_val - min_val)\n",
    "    return _inner_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize quaternion distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quaternion distance is calculated with:\n",
    "    $$ d_{i, j} = 2 \\arccos{|\\langle\\,q_i,q_j\\rangle}| $$\n",
    "\n",
    "Therefore, the min value is $0$ and the max value is $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing quaternion distance\n",
    "normalize_quaternion_distance = normalize(min_val=0.0, max_val=np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize projection distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projection distance is calculatd with:\n",
    "    $$ d_{i,j} = \\sqrt{(p_i - p_j)^2}\n",
    "    $$\n",
    "where $p = (p_1, p_2, ..., p_n)$ has the size of $N_{pixels}$ and $p_1, p_2,.., p_n  \\epsilon  [0, 1, .., 255]$.\n",
    "\n",
    "Therefore, the min value is $0$ and max value is $255\\sqrt{N_{pixels}}$. If the projection image size is 136x136, then $N_{pixels} = 136 \\cdot 136 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize projections distance\n",
    "normalize_projection_distance = normalize(min_val=0.0, max_val=255.0 * np.sqrt(n_pixels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to then optimize\n",
    "$$ \\operatorname*{arg\\,min}_{\\{\\hat{Q}_i\\}_{i=1}^n} \\sum_{i,j} \\left| d_p(p_i, p_j) - d_Q(\\hat{Q}_i, \\hat{Q}_j) \\right|^2, $$\n",
    "where $p_i$ is a projected image and $d_p$ is a (learned) distance between two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(q1_predicted, q2_predicted, distance_target):\n",
    "    q1 = quaternion.normalize(q1_predicted)\n",
    "    q2 = quaternion.normalize(q2_predicted)\n",
    "    distance = d_q(q1, q2)\n",
    "    \n",
    "    distance        = normalize_quaternion_distance(distance)\n",
    "    distance_target = normalize_projection_distance(distance_target)\n",
    "    \n",
    "    # The mean doesn't depend on the batch size.\n",
    "    return tf.reduce_mean((distance - distance_target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(q1_predicted, q2_predicted, distance_target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(q1_predicted, q2_predicted, distance_target)\n",
    "        gradient = tape.gradient(loss_value, q1_predicted + q2_predicted)\n",
    "        \n",
    "    return loss_value, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "steps = 5000\n",
    "\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "# Random initialization.\n",
    "angles_predicted = [tf.Variable(quaternion.normalized_random_uniform([1])) for _ in range(n_samples)]\n",
    "\n",
    "losses = np.empty(steps)\n",
    "time_start = time()\n",
    "\n",
    "for step in range(1, steps+1):\n",
    "\n",
    "    # Sample some pairs.\n",
    "    idx1 = list(np.random.randint(0, n_samples, batch_size))\n",
    "    idx2 = list(np.random.randint(0, n_samples, batch_size))\n",
    "    q1 = [angles_predicted[i] for i in idx1]\n",
    "    q2 = [angles_predicted[i] for i in idx2]\n",
    "    \n",
    "    q1 = asserts.assert_normalized(q1)\n",
    "    q2 = asserts.assert_normalized(q2)\n",
    "\n",
    "    # Compute distances between pairs.\n",
    "    # To be replaced by distance estimation in pixel space.\n",
    "    p1 = [projections[i] for i in idx1]\n",
    "    p2 = [projections[i] for i in idx2]\n",
    "    distance_target = d_p(p1, p2)\n",
    "\n",
    "    # Optimize by gradient descent.\n",
    "    losses[step-1], gradients = gradient(q1, q2, distance_target)\n",
    "    optimizer.apply_gradients(zip(gradients, q1 + q2))\n",
    "\n",
    "    q1 = quaternion.normalize(q1)\n",
    "    q2 = quaternion.normalize(q2)\n",
    "\n",
    "    # Periodically report progress.\n",
    "    if ((step % (steps//10)) == 0) or (step == steps):\n",
    "        time_elapsed = time() - time_start\n",
    "        print(f'step {step}/{steps} ({time_elapsed:.0f}s): loss = {losses[step-1]:.2e}')\n",
    "\n",
    "    #if step> 400:break;\n",
    "# Plot convergence.\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.linspace(0, time()-time_start, steps), losses)\n",
    "ax.set_xlabel('time [s]')\n",
    "ax.set_ylabel('loss');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
