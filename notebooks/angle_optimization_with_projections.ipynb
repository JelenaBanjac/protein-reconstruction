{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding angles with gradient descent (projections & quaternions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: To use the exr data format, please install the OpenEXR package following the instructions detailed in the README at github.com/tensorflow/graphics.\n",
      "Warning: To use the threejs_vizualization, please install the colabtools package following the instructions detailed in the README at github.com/tensorflow/graphics.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import h5py\n",
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow_graphics.geometry.transformation import quaternion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Angles / Quaternions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 tensors of shape (4,)\n"
     ]
    }
   ],
   "source": [
    "low_ang = np.pi/2\n",
    "high_ang = 2*np.pi-np.pi/2\n",
    "\n",
    "euler = np.random.uniform(low=[low_ang, low_ang, low_ang], \n",
    "                          high=[high_ang, high_ang, high_ang],\n",
    "                          size=(n_samples,3))\n",
    "angles_true = [quaternion.from_euler(e) for e in euler]\n",
    "\n",
    "print(f'{len(angles_true)} tensors of shape {angles_true[0].shape}')\n",
    "\n",
    "# Sanity check: the quaternions represent rotations, i.e., are normalized.\n",
    "assert abs(tf.reduce_mean(tf.norm(angles_true, axis=1) - tf.ones(n_samples, dtype=np.float64))) < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angles_true = np.array(angles_true)\n",
    "angles = np.reshape(angles_true, (angles_true.shape[0], -1))\n",
    "angles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 projections of images with dimension (136, 136) pixels\n"
     ]
    }
   ],
   "source": [
    "# location of *.h5 files\n",
    "data_dir = \"../data\"\n",
    "\n",
    "# half coverage (AngCoverage=0.5)\n",
    "projections_filename = \"ProjectionsAngles_ProjNber5000_AngCoverage0.5_AngShift1.57\"\n",
    "\n",
    "# load structures\n",
    "data = h5py.File(os.path.join(data_dir, f\"{projections_filename}.h5\"), 'r')\n",
    "\n",
    "print(f\"{data['Projections'].shape[0]} projections of images with dimension {data['Projections'].shape[1:]} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 18496)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projections = np.reshape(data[\"Projections\"], (data[\"Projections\"].shape[0], -1))\n",
    "projections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pixels = projections.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Angle Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_graphics.util import asserts\n",
    "from tensorflow_graphics.math import vector\n",
    "from tensorflow_graphics.util import safe_ops\n",
    "from tensorflow_graphics.util import shape\n",
    "\n",
    "def d_q(q1, q2):\n",
    "     with (tf.compat.v1.name_scope(None, \"quaternion_relative_angle\",\n",
    "                                 [q1, q2])):\n",
    "        q1 = tf.convert_to_tensor(value=q1)\n",
    "        q2 = tf.convert_to_tensor(value=q2)\n",
    "      \n",
    "        shape.check_static(\n",
    "            tensor=q1, tensor_name=\"quaternion1\", has_dim_equals=(-1, 4))\n",
    "        shape.check_static(\n",
    "            tensor=q2, tensor_name=\"quaternion2\", has_dim_equals=(-1, 4))\n",
    "\n",
    "        q1 = quaternion.normalize(q1)\n",
    "        q2 = quaternion.normalize(q2)\n",
    "        \n",
    "        dot_product = vector.dot(q1, q2, keepdims=False)\n",
    "        \n",
    "        # Ensure dot product is in range [-1. 1].\n",
    "        const = 1.8 #4.0 #.63\n",
    "        eps_dot_prod = const * asserts.select_eps_for_addition(dot_product.dtype)\n",
    "        dot_product = safe_ops.safe_shrink(\n",
    "            dot_product, -1, 1, open_bounds=False, eps=eps_dot_prod)\n",
    "\n",
    "        return 2.0 * tf.acos(tf.abs(dot_product))\n",
    "    \n",
    "assert tf.reduce_mean(d_q(angles_true[0:3], angles_true[0:3])) < 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.664001874625056e-08, shape=(), dtype=float64)\n",
      "tf.Tensor(1.1764182366022029e-07, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_mean(d_q(angles_true[0:3], angles_true[0:3])))\n",
    "print(tf.reduce_mean(quaternion.relative_angle(angles_true[0:3], angles_true[0:3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projection Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_p(p1, p2):\n",
    "    # (learned) distance between two images.\n",
    "    # for now, Euclid dist\n",
    "    p1 = tf.convert_to_tensor(value=p1, dtype=np.float32)\n",
    "    p2 = tf.convert_to_tensor(value=p2, dtype=np.float32)\n",
    "\n",
    "    if len(p1.shape) > 1:\n",
    "        dist = tf.norm(p1-p2, ord='euclidean', axis=1, keepdims=True)\n",
    "    else:\n",
    "        dist = tf.norm(p1-p2, ord='euclidean')\n",
    "\n",
    "    return dist\n",
    "\n",
    "assert tf.reduce_mean(d_p(projections[0:3], projections[0:3])) < 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(d_p(projections[0:3], projections[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjacency matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 10542.376056194305 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "projections_filename = \"projections1\"\n",
    "\n",
    "if not os.path.exists(f'data/{projections_filename}_distances.npy'):\n",
    "    nbrs = NearestNeighbors(n_neighbors=5, metric=d_p, algorithm='ball_tree').fit(projections)\n",
    "    distances_p, indices_p = nbrs.kneighbors(projections)\n",
    "    A_p = nbrs.kneighbors_graph(projections).toarray()\n",
    "    \n",
    "    np.save(f'data/{projections_filename}_indices', indices_p)         # Indices of the nearest points in the population matrix\n",
    "    np.save(f'data/{projections_filename}_distances', distances_p)     # Array representing the lengths to points\n",
    "    np.save(f'data/{projections_filename}_A', A_p) # Sparse graph showing the connections between neighboring points\n",
    "    \n",
    "else:\n",
    "    indices_p     = np.load(f'data/{projections_filename}_indices.npy')     # shape: NUM_IMGS, NUM_NEIGHBOURS\n",
    "    distances_p   = np.load(f'data/{projections_filename}_distances.npy')   # shape: NUM_IMGS, NUM_NEIGHBOURS\n",
    "    A_p           = np.load(f'data/{projections_filename}_A.npy') # shape: NUM_IMGS, NUM_IMGS\n",
    "    \n",
    "print(f\"--- {time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4102.318271160126 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "angles_filename = \"angles1\"\n",
    "\n",
    "if not os.path.exists(f'data/{angles_filename}_distances.npy'):\n",
    "    nbrs = NearestNeighbors(n_neighbors=5, metric=d_q, algorithm='ball_tree').fit(angles)\n",
    "    distances_a, indices_a = nbrs.kneighbors(angles)\n",
    "    A_a = nbrs.kneighbors_graph(angles).toarray()\n",
    "    \n",
    "    np.save(f'data/{angles_filename}_indices', indices_a)         # Indices of the nearest points in the population matrix\n",
    "    np.save(f'data/{angles_filename}_distances', distances_a)     # Array representing the lengths to points\n",
    "    np.save(f'data/{angles_filename}_A', A_a) # Sparse graph showing the connections between neighboring points\n",
    "    \n",
    "else:\n",
    "    indices_a     = np.load(f'data/{angles_filename}_indices.npy')     # shape: NUM_IMGS, NUM_NEIGHBOURS\n",
    "    distances_a   = np.load(f'data/{angles_filename}_distances.npy')   # shape: NUM_IMGS, NUM_NEIGHBOURS\n",
    "    A_a           = np.load(f'data/{angles_filename}_A.npy') # shape: NUM_IMGS, NUM_IMGS\n",
    "    \n",
    "print(f\"--- {time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To normalize our distances, we simply calculate the following:\n",
    "\n",
    "$$ z_{i} = \\frac{d_i - min(d)}{max(d) - min(d)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(min_val, max_val):\n",
    "    def _inner_normalize(dist):\n",
    "        return (dist - min_val)/(max_val - min_val)\n",
    "    return _inner_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize quaternion distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quaternion distance is calculated with:\n",
    "    $$ d_{i, j} = 2 \\arccos{|\\langle\\,q_i,q_j\\rangle}| $$\n",
    "\n",
    "Therefore, the min value is $0$ and the max value is $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing quaternion distance\n",
    "normalize_quaternion_distance = normalize(min_val=0.0, max_val=np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize projection distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projection distance is calculatd with:\n",
    "    $$ d_{i,j} = \\sqrt{(p_i - p_j)^2}\n",
    "    $$\n",
    "where $p = (p_1, p_2, ..., p_n)$ has the size of $N_{pixels}$ and $p_1, p_2,.., p_n  \\epsilon  [0, 1, .., 255]$.\n",
    "\n",
    "Therefore, the min value is $0$ and max value is $255\\sqrt{N_{pixels}}$. If the projection image size is 136x136, then $N_{pixels} = 136 \\cdot 136 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize projections distance\n",
    "normalize_projection_distance = normalize(min_val=0.0, max_val=255.0 * np.sqrt(n_pixels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to then optimize\n",
    "$$ \\operatorname*{arg\\,min}_{\\{\\hat{Q}_i\\}_{i=1}^n} \\sum_{i,j} \\left| d_p(p_i, p_j) - d_Q(\\hat{Q}_i, \\hat{Q}_j) \\right|^2, $$\n",
    "where $p_i$ is a projected image and $d_p$ is a (learned) distance between two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(q1_predicted, q2_predicted, distance_target):\n",
    "    q1 = quaternion.normalize(q1_predicted)\n",
    "    q2 = quaternion.normalize(q2_predicted)\n",
    "    distance = d_q(q1, q2)\n",
    "    \n",
    "    distance        = normalize_quaternion_distance(distance)\n",
    "    distance_target = normalize_projection_distance(distance_target)\n",
    "    \n",
    "    # The mean doesn't depend on the batch size.\n",
    "    return tf.reduce_mean((distance - distance_target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(q1_predicted, q2_predicted, distance_target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(q1_predicted, q2_predicted, distance_target)\n",
    "        gradient = tape.gradient(loss_value, q1_predicted + q2_predicted)\n",
    "        \n",
    "    return loss_value, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 200/2000 (153s): loss = 5.06e-01\n",
      "step 400/2000 (297s): loss = 4.76e-01\n",
      "step 600/2000 (441s): loss = 3.68e-01\n",
      "step 800/2000 (586s): loss = 1.11e-01\n",
      "step 1000/2000 (729s): loss = 2.24e-02\n",
      "step 1200/2000 (875s): loss = 1.76e-03\n",
      "step 1400/2000 (1019s): loss = 7.28e-04\n",
      "step 1600/2000 (1164s): loss = 2.77e-05\n",
      "step 1800/2000 (1312s): loss = 1.27e-05\n",
      "step 2000/2000 (1463s): loss = 8.15e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "steps = 5000\n",
    "\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "# Random initialization.\n",
    "angles_predicted = [tf.Variable(quaternion.normalized_random_uniform([1])) for _ in range(n_samples)]\n",
    "\n",
    "losses = np.empty(steps)\n",
    "time_start = time()\n",
    "\n",
    "for step in range(1, steps+1):\n",
    "\n",
    "    # Sample some pairs.\n",
    "    idx1 = list(np.random.randint(0, n_samples, batch_size))\n",
    "    idx2 = list(np.random.randint(0, n_samples, batch_size))\n",
    "    q1 = [angles_predicted[i] for i in idx1]\n",
    "    q2 = [angles_predicted[i] for i in idx2]\n",
    "    \n",
    "    q1 = asserts.assert_normalized(q1)\n",
    "    q2 = asserts.assert_normalized(q2)\n",
    "\n",
    "    # Compute distances between pairs.\n",
    "    # To be replaced by distance estimation in pixel space.\n",
    "    p1 = [projections[i] for i in idx1]\n",
    "    p2 = [projections[i] for i in idx2]\n",
    "    distance_target = d_p(p1, p2)\n",
    "\n",
    "    # Optimize by gradient descent.\n",
    "    losses[step-1], gradients = gradient(q1, q2, distance_target)\n",
    "    optimizer.apply_gradients(zip(gradients, q1 + q2))\n",
    "\n",
    "    q1 = quaternion.normalize(q1)\n",
    "    q2 = quaternion.normalize(q2)\n",
    "\n",
    "    # Periodically report progress.\n",
    "    if ((step % (steps//10)) == 0) or (step == steps):\n",
    "        time_elapsed = time() - time_start\n",
    "        print(f'step {step}/{steps} ({time_elapsed:.0f}s): loss = {losses[step-1]:.2e}')\n",
    "\n",
    "    #if step> 400:break;\n",
    "# Plot convergence.\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.linspace(0, time()-time_start, steps), losses)\n",
    "ax.set_xlabel('time [s]')\n",
    "ax.set_ylabel('loss');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
