{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding angles with gradient descent (projections & quaternions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Michaël Defferrard](https://deff.ch), EPFL LTS2  \n",
    "[Laurène Donati](https://people.epfl.ch/laurene.donati), EPFL BIG  \n",
    "[Jelena Banjac](https://people.epfl.ch/jelena.banjac), EPFL MSc in Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import h5py\n",
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow_graphics.util import asserts\n",
    "from tensorflow_graphics.math import vector\n",
    "from tensorflow_graphics.util import safe_ops\n",
    "from tensorflow_graphics.util import shape\n",
    "from tensorflow_graphics.geometry.transformation import quaternion, euler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of *.h5 files\n",
    "data_dir = \"../data\"\n",
    "\n",
    "# half coverage (AngCoverage=0.5)\n",
    "projections_filename = \"ProjectionsAngles_ProjNber5000_AngCoverage0.5_AngShift1.57\"\n",
    "\n",
    "# load structures\n",
    "data = h5py.File(os.path.join(data_dir, f\"{projections_filename}.h5\"), 'r')\n",
    "\n",
    "print(f\"{data['Projections'].shape[0]} projections of images with dimension {data['Projections'].shape[1:]} pixels\")\n",
    "print(f\"{data['Angles'].shape[0]} sets of {data['Angles'].shape[1]} ground truth angles of corresponding projection images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predicted Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_ang = np.pi/2\n",
    "high_ang = 2*np.pi-np.pi/2\n",
    "\n",
    "euler = np.random.uniform(low=[low_ang, low_ang, low_ang], \n",
    "                          high=[high_ang, high_ang, high_ang],\n",
    "                          size=(n_samples, 3))\n",
    "\n",
    "# angles_predicted = [tf.Variable(e, constraint=lambda x: tf.clip_by_value(x, low_ang, high_ang)) for e in euler]\n",
    "angles_predicted = [tf.Variable(e) for e in euler]\n",
    "print(f\"Angles predicted: (min, max) = ({tf.reduce_min(angles_predicted):.4f}, {tf.reduce_max(angles_predicted):.4f})\")\n",
    "\n",
    "angles_predicted = np.array(angles_predicted)\n",
    "angles_predicted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### True Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_true = np.reshape(data[\"Angles\"], (data[\"Angles\"].shape[0], -1))\n",
    "print(f\"Angles true: (min, max) = ({np.min(angles_true):.4f}, {np.max(angles_true):.4f})\")\n",
    "\n",
    "angles_true = np.array(angles_true)\n",
    "angles_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = np.reshape(data[\"Projections\"], (data[\"Projections\"].shape[0], -1))\n",
    "print(f\"Projections: (min, max) = ({np.min(projections):.4f}, {np.max(projections):.4f})\")\n",
    "\n",
    "projections = np.array(projections)\n",
    "projections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pixels = projections.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Angle Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_q(q1, q2):\n",
    "     with (tf.compat.v1.name_scope(None, \"quaternion_relative_angle\",\n",
    "                                 [q1, q2])):\n",
    "        q1 = tf.convert_to_tensor(value=q1)\n",
    "        q2 = tf.convert_to_tensor(value=q2)\n",
    "      \n",
    "        shape.check_static(\n",
    "            tensor=q1, tensor_name=\"quaternion1\", has_dim_equals=(-1, 4))\n",
    "        shape.check_static(\n",
    "            tensor=q2, tensor_name=\"quaternion2\", has_dim_equals=(-1, 4))\n",
    "\n",
    "        q1 = quaternion.normalize(q1)\n",
    "        q2 = quaternion.normalize(q2)\n",
    "        \n",
    "        dot_product = vector.dot(q1, q2, keepdims=False)\n",
    "        \n",
    "        # Ensure dot product is in range [-1. 1].\n",
    "        const = 1.8 #4.0 #.63\n",
    "        eps_dot_prod = const * asserts.select_eps_for_addition(dot_product.dtype)\n",
    "        dot_product = safe_ops.safe_shrink(\n",
    "            dot_product, -1, 1, open_bounds=False, eps=eps_dot_prod)\n",
    "\n",
    "        return 2.0 * tf.acos(tf.abs(dot_product))\n",
    "    \n",
    "assert tf.reduce_mean(d_q(quaternion.from_euler(angles_true[0:3]), quaternion.from_euler(angles_true[0:3]))) < 1e-7\n",
    "assert (d_q(quaternion.from_euler([np.pi/2]*3), quaternion.from_euler([2*np.pi-np.pi/2]*3))-np.pi) < 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projection Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_p(p1, p2):\n",
    "    # (learned) distance between two images.\n",
    "    # for now, Euclid dist\n",
    "    p1 = tf.convert_to_tensor(value=p1, dtype=np.float64)\n",
    "    p2 = tf.convert_to_tensor(value=p2, dtype=np.float64)\n",
    "\n",
    "    if len(p1) > 1:\n",
    "        dist = tf.norm(p1-p2, ord='euclidean', axis=1, keepdims=True)\n",
    "    else:\n",
    "        dist = tf.norm(p1-p2, ord='euclidean')\n",
    "\n",
    "    return dist\n",
    "\n",
    "assert tf.reduce_mean(d_p(projections[0:3], projections[0:3])) < 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient of Slope d_p/d_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cpq = 19.964992681300494"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to then optimize\n",
    "$$ \\operatorname*{arg\\,min}_{\\{\\hat{Q}_i\\}_{i=1}^n} \\sum_{i,j} \\left| d_p(p_i, p_j) - d_Q(\\hat{Q}_i, \\hat{Q}_j) \\right|^2, $$\n",
    "where $p_i$ is a projected image and $d_p$ is a (learned) distance between two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(a1_predicted, a2_predicted, distance_target, normalize=None):\n",
    "    q1 = quaternion.from_euler(a1_predicted)\n",
    "    q2 = quaternion.from_euler(a2_predicted)\n",
    "\n",
    "    q1 = quaternion.normalize(q1)\n",
    "    q2 = quaternion.normalize(q2)\n",
    "    \n",
    "    distance = d_q(q1, q2)\n",
    "    \n",
    "    if normalize:\n",
    "        #distance = normalize_quaternion_distance(distance)\n",
    "        #distance_target = normalize(distance_target)\n",
    "        distance_target = distance_target/Cpq\n",
    "    \n",
    "    # The mean doesn't depend on the batch size.\n",
    "    return tf.reduce_mean((distance - distance_target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(a1_predicted, a2_predicted, distance_target, normalize=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(a1_predicted, a2_predicted, distance_target, normalize)\n",
    "        gradient = tape.gradient(loss_value, a1_predicted + a2_predicted)\n",
    "        \n",
    "    return loss_value, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Before] Prediction vs. True Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_predicted_vs_true_angle(steps, batch_size):\n",
    "    losses = np.empty(steps)\n",
    "    time_start = time()\n",
    "    \n",
    "    for step in range(1, steps+1):\n",
    "\n",
    "        # Sample some pairs.\n",
    "        idx1 = list(np.random.randint(0, n_samples, batch_size))\n",
    "        idx2 = list(np.random.randint(0, n_samples, batch_size))\n",
    "        a1 = [angles_predicted[i] for i in idx1]\n",
    "        a2 = [angles_predicted[i] for i in idx2]\n",
    "\n",
    "        # Compute distances between true quaternions\n",
    "        a1_true = [angles_true[i] for i in idx1]\n",
    "        a2_true = [angles_true[i] for i in idx2]\n",
    "        q1_true = quaternion.from_euler(a1_true)\n",
    "        q2_true = quaternion.from_euler(a2_true)\n",
    "        q1_true = quaternion.normalize(q1_true)\n",
    "        q2_true = quaternion.normalize(q2_true)\n",
    "        \n",
    "        distance_target = d_q(q1_true, q2_true)\n",
    "\n",
    "        # Optimize by gradient descent.\n",
    "        losses[step-1] = loss(a1, a2, distance_target)\n",
    "        \n",
    "        # Periodically report progress.\n",
    "        if ((step % (steps//10)) == 0) or (step == steps):\n",
    "            time_elapsed = time() - time_start\n",
    "            print(f'step {step}/{steps} ({time_elapsed:.0f}s): loss = {losses[step-1]:.2e}')\n",
    "\n",
    "    print(f\"Mean loss: {np.mean(losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization loop (projection-true & angles-predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_predicted_vs_true_angle(steps=2000, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=2000\n",
    "batch_size=256\n",
    "\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "losses = np.empty(steps)\n",
    "time_start = time()\n",
    "\n",
    "for step in range(1, steps+1):\n",
    "\n",
    "    # Sample some pairs.\n",
    "    idx1 = list(np.random.randint(0, n_samples, batch_size))\n",
    "    idx2 = list(np.random.randint(0, n_samples, batch_size))\n",
    "    a1 = [angles_predicted[i] for i in idx1]\n",
    "    a2 = [angles_predicted[i] for i in idx2]\n",
    "    \n",
    "    # Compute distances between projections\n",
    "    p1 = [projections[i] for i in idx1]\n",
    "    p2 = [projections[i] for i in idx2]\n",
    "    \n",
    "    distance_target = d_p(p1, p2)\n",
    "\n",
    "    # Optimize by gradient descent.\n",
    "    losses[step-1], gradients = gradient(a1, a2, distance_target, normalize=True)\n",
    "    optimizer.apply_gradients(zip(gradients, a1 + a2))\n",
    "\n",
    "    # Periodically report progress.\n",
    "    if ((step % (steps//10)) == 0) or (step == steps):\n",
    "        time_elapsed = time() - time_start\n",
    "        print(f'step {step}/{steps} ({time_elapsed:.0f}s): loss = {losses[step-1]:.2e}')\n",
    "\n",
    "# Plot convergence.\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.linspace(0, time()-time_start, steps), losses)\n",
    "ax.set_xlabel('time [s]')\n",
    "ax.set_ylabel('loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [After] Prediction vs. True Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_predicted_vs_true_angle(steps=2000, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare d_Q and d_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=5000\n",
    "\n",
    "d_q_list = []\n",
    "d_p_list = []\n",
    "\n",
    "# Sample some pairs.\n",
    "idx1 = list(np.random.randint(0, n_samples, batch_size))\n",
    "idx2 = list(np.random.randint(0, n_samples, batch_size))\n",
    "a1 = [angles_true[i] for i in idx1]\n",
    "a2 = [angles_true[i] for i in idx2]\n",
    "q1 = quaternion.from_euler(a1)\n",
    "q2 = quaternion.from_euler(a2)\n",
    "q1 = quaternion.normalize(q1)\n",
    "q2 = quaternion.normalize(q2)\n",
    "distance_target_q = d_q(q1, q2)\n",
    "d_q_list.append(distance_target_q)\n",
    "\n",
    "# Compute distances between projections\n",
    "p1 = [projections[i] for i in idx1]\n",
    "p2 = [projections[i] for i in idx2]\n",
    "distance_target_p = d_p(p1, p2)\n",
    "d_p_list.append(distance_target_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(d_q_list[0], d_p_list[0], marker=\"*\", markersize=2, lw=0)\n",
    "plt.xlabel('d_Q')\n",
    "plt.ylabel('d_P');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd; np.random.seed(0)\n",
    "import seaborn as sns; sns.set(style=\"white\", color_codes=True)\n",
    "\n",
    "data = {\"d_Q\" : list(d_q_list[0][:5000].numpy()),\n",
    "        \"d_P\" : [x[0] for x in list(d_p_list[0][:5000].numpy())]}\n",
    "df = pd.DataFrame(data=data)\n",
    "sns.jointplot(x=\"d_Q\", y=\"d_P\", data=df, kind=\"kde\", color=\"g\", height=11)  # \"reg\", \"kde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=20000\n",
    "\n",
    "d_q_list = []\n",
    "d_p_list = []\n",
    "\n",
    "# Sample some pairs.\n",
    "idx1 = list(np.random.randint(0, n_samples, batch_size))\n",
    "idx2 = list(np.random.randint(0, n_samples, batch_size))\n",
    "a1 = [angles_true[i] for i in idx1]\n",
    "a2 = [angles_true[i] for i in idx2]\n",
    "q1 = quaternion.from_euler(a1)\n",
    "q2 = quaternion.from_euler(a2)\n",
    "q1 = quaternion.normalize(q1)\n",
    "q2 = quaternion.normalize(q2)\n",
    "distance_target_q = d_q(q1, q2)\n",
    "d_q_list.append(distance_target_q)\n",
    "\n",
    "# Compute distances between projections\n",
    "p1 = [projections[i] for i in idx1]\n",
    "p2 = [projections[i] for i in idx2]\n",
    "distance_target_p = d_p(p1, p2)\n",
    "d_p_list.append(distance_target_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(d_q_list[0], d_p_list[0], marker=\"*\", markersize=2, lw=0)\n",
    "plt.xlabel('d_Q')\n",
    "plt.ylabel('d_P');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"d_Q\" : list(d_q_list[0][:5000].numpy()),\n",
    "        \"d_P\" : [x[0] for x in list(d_p_list[0][:5000].numpy())]}\n",
    "df = pd.DataFrame(data=data)\n",
    "sns.jointplot(x=\"d_Q\", y=\"d_P\", data=df, kind=\"kde\", color=\"g\", height=11)  # \"reg\", \"kde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"d_Q\" : list(d_q_list[0][:5000].numpy()),\n",
    "        \"d_P\" : [x[0] for x in list(d_p_list[0][:5000].numpy())]}\n",
    "df = pd.DataFrame(data=data)\n",
    "sns.jointplot(x=\"d_Q\", y=\"d_P\", data=df, kind=\"reg\", color=\"g\", height=11)  # \"reg\", \"kde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, slope_std_error = stats.linregress(df[\"d_Q\"],df[\"d_P\"])\n",
    "print(f\"d_P/d_Q = {slope}, intercept = {intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
